
We thank all reviewers for their elaborate reviews and valuable feedback. In short, we are pleased to see the interest generated by implicit minimax backups in MCTS. In this response, we answer questions and explain our position on several points brought up by the reviewers. 

We agree with many interesting suggestions and hope to address them in a potential comprehensive (journal) follow-up paper. For this first six-page conference paper, we chose to focus on a thorough evaluation across several domains and clearly show the promise of the approach for improving practical performance. We intentionally chose to trade depth of analysis in one domain for breadth across several domains, which resulted in general observations and patterns such as the relationship between alpha and performance gain (and more specifically, the effect as a function of the amount/level of domain knowledge.)

If accepted, we will clarify the "Empirical Evaluation" and improve the "Conclusion" sections.

In Breakthrough, the average simulations/second varies between 30000-80000, depending on the enhancements used. In Kalah and LOA, these are approximately 120000 and X. 

Regarding the comparison to minimax, LOA is well-known the search and game-playing community and has been extensively researched. It is especially relevant given previous work comparing MCTS/minimax. Experiments were performed in MC-LOA, a world-champion engine winning the last X Olympiads. The benchmark minimax player is MIA, the world-best minimax-player. Both use state-of-the-art techniques, including highly-optimized and competitive dynamic alpha-beta playouts as well as a sophisticated evaluation function based on Y years of research. 

We have tested against two different evaluation functions in Breakthrough: one simple one, and one sophisticated one taken from a current state-of-the-art engine (see "Empirical Evaluation".) Both are computed incrementally and add approximately 0.058% of overhead. 

Regarding terminal states, they are indeed considered perfect values (proven wins/losses/draws). These are back-propagated by MCTS-Solver (see Winands et al. 2008a, also explained in "Related Work") which override both heuristic values and Monte Carlo estimates. 

Regarding baselines in Breakthrough: in "Empirical Evaluation" we explain how we obtain the the best combination of these methods, with details in the appendix (to be released in a technical report if accepted). Our default playout policy beats uniform random 94.3% of the time. Our best combination (ege0.1,det0.5) beats our default playout policy 85.6% of the time. We will clarify this. 

To the best of our understanding, value initialization ("virtual playouts") in the cited paper is equivalent to node priors, which we compare to in Breakthrough. 

While Kalah has is less explored than Breakthrough+Kalah, we believe it nonetheless helps characterize the type of domain this approach is expected to work in and complements relevant previous MCTS/minimax comparisons in this domain (Ramanujan & Selman 2011). Also, it gives a third domain with a similar pattern for alpha vs. performance.

We admit that explaining the precise cause/source of the improvement requires further work. However, overall, the paper does show that the approach leads to clear performance gains compared to state-of-the-art techniques, with recurring patters across three domains and varying experimental configurations. 


